<html>
  <head>
    <meta charset="UTF-8" />
    <title>PoseNet example using p5.js</title>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/addons/p5.dom.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.10.2/addons/p5.sound.min.js"></script>
    <script src="edfdecoder.umd.min.js"></script>
    <script
      src="https://unpkg.com/ml5@latest/dist/ml5.min.js"
      type="text/javascript"></script>
  </head>

  <body>
    <h1>Multimodal Signals Visualization</h1>
    <p>This demo uses three different signals:</p>
    <ul>
        <li>The position of your nose (captured by your webcam)</li>
        <li>The volume of your voice (captured by your microphone)</li>
        <li>A recording of a Emotiv session (EDF file)</li>
    </ul>
    <p>If you move your nose to the left the amount of purple flares will increase.
        If you increase your voice, a green halo will appear.
        The background changes to the values of the measurements in the channel 0 of the EEG.</p>
    <p>After the posture detecting model is loaded, click on the image to start the audio processing.</p>
    <p id="status">Wait for the model to download...</p>
    <script src="sketch.js"></script>
  </body>
</html>